{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from pyproj import CRS, Transformer\n",
    "from shapely.geometry import LineString, Point, MultiLineString\n",
    "import math\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Manhattan road network with Uber link speed (not a complete link network, contains missing links)\n",
    "graph_proj_v2 = ox.load_graphml('manhattan_v2.graphml')\n",
    "nodes_proj_new,edges_proj_new = ox.graph_to_gdfs(graph_proj_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph of Manhattan Road Network\n",
    "graph = ox.load_graphml('manhattan.osm')\n",
    "graph_proj = ox.project_graph(graph,to_crs=CRS.from_epsg(2263))\n",
    "# Create graph with travel time\n",
    "graph_proj_speed = ox.add_edge_speeds(graph_proj)\n",
    "graph_proj = ox.add_edge_travel_times(graph_proj_speed)\n",
    "nodes_proj,edges_proj = ox.graph_to_gdfs(graph_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace osm maxspeed with Uber speed\n",
    "for index,row in edges_proj.iterrows():\n",
    "    travel_t = edges_proj_new.loc[edges_proj_new['u'] ==row.u]\n",
    "    travel_t = travel_t.loc[travel_t['v'] ==row.v] \n",
    "    if travel_t.empty:\n",
    "        if isinstance(row.maxspeed,list):\n",
    "            edges_proj.loc[index,['maxspeed']] = row.maxspeed[0]\n",
    "        else:\n",
    "            edges_proj.loc[index,['maxspeed']] = row.maxspeed\n",
    "    else:\n",
    "        edges_proj.loc[index,['maxspeed']] = travel_t.maxspeed.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network and calculate missing link speeds\n",
    "graph_proj = ox.graph_from_gdfs(nodes_proj,edges_proj)\n",
    "graph_proj_speed = ox.add_edge_speeds(graph_proj)\n",
    "graph_proj = ox.add_edge_travel_times(graph_proj_speed)\n",
    "nodes_proj,edges_proj = ox.graph_to_gdfs(graph_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests and vehicle locations\n",
    "man_veh = pd.read_csv('Manhattan_dropoff_14_80000-80030.csv',index_col='index')\n",
    "man_req = pd.read_csv('Manhattan_pickup_14_80000-80030.csv',index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following sections contain functions used to prepare and process input data for Google OR-TOOLS\n",
    "# convert request dataframe into a geodataframe with projected coordinates and linestring\n",
    "def convert_req_coord(requests):\n",
    "    transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:2263\")\n",
    "    request_proj=pd.DataFrame()\n",
    "    request_geom=[]\n",
    "    for index,row in requests.iterrows():\n",
    "        \n",
    "        request_proj.loc[index,'pickup_x'],request_proj.loc[index,'pickup_y']=transformer.transform(row['pickup_latitude'],row['pickup_longitude'])\n",
    "        request_proj.loc[index,'dropoff_x'],request_proj.loc[index,'dropoff_y']=transformer.transform(row['dropoff_latitude'],row['dropoff_longitude'])\n",
    "        pickup = list(np.around(np.array(request_proj.loc[index,['pickup_x','pickup_y']].to_list()),2))\n",
    "        dropoff = list(np.around(np.array(request_proj.loc[index,['dropoff_x','dropoff_y']].to_list()),2))\n",
    "        line = LineString([pickup,dropoff])\n",
    "        request_geom.append(line)\n",
    "    request_geom_df=gpd.GeoDataFrame(request_proj, geometry=request_geom,crs=\"EPSG:2263\")\n",
    "    request_geom_df['pickup_datetime'] = requests['pickup_datetime']\n",
    "    return request_geom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot requests\n",
    "def plot_mahattan_projected(graph,gdf):\n",
    "    fig,ax=plt.subplots(figsize=(30,20))\n",
    "    nodes,edges = ox.graph_to_gdfs(graph)\n",
    "    nodes.plot(ax=ax,color='#7DD9FC',markersize=0.5, zorder=10)\n",
    "    edges.plot(ax=ax,linewidth=1,color='#B4B3B3',alpha=0.7, zorder=5)\n",
    "    if 'pickup_x' in gdf.columns:\n",
    "        ax.scatter(gdf['pickup_x'],gdf['pickup_y'],marker=\">\",zorder=15)\n",
    "        ax.scatter(gdf['dropoff_x'],gdf['dropoff_y'],marker=\"*\",color=\"orange\",zorder=15)\n",
    "    elif 'pickup_node' in gdf.columns:\n",
    "        nodes.loc[gdf['pickup_node']].plot(ax=ax,marker=\">\",zorder=15)\n",
    "        nodes.loc[gdf['dropoff_node']].plot(ax=ax,marker=\"*\",color=\"orange\",zorder=15)\n",
    "    elif 'veh_node' in gdf.columns:\n",
    "        nodes.loc[gdf['veh_node']].plot(ax=ax,marker=\".\",color=\"magenta\",zorder=15)\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert projected coordinates to nodes and find shortest paths\n",
    "# Input graph must be projected and contain edge travel times\n",
    "def map_matching_paths(graph,req_gdf):\n",
    "    nodes,edges = ox.graph_to_gdfs(graph)\n",
    "    route_line_request=[]\n",
    "    nodes_pair=[]\n",
    "    nodes_time=[]\n",
    "    path = []\n",
    "    count = 0\n",
    "    req_gdf['dropp']=0\n",
    "    #convert projected coordinates to nodes\n",
    "    for index,row in req_gdf.iterrows():\n",
    "        pickup_node = ox.get_nearest_node(graph,(row['pickup_y'],row['pickup_x']),method='euclidean')\n",
    "        dropoff_node = ox.get_nearest_node(graph,(row['dropoff_y'],row['dropoff_x']),method='euclidean')\n",
    "        if pickup_node == dropoff_node:\n",
    "            req_gdf.loc[index,'dropp'] = 1\n",
    "            count += 1\n",
    "            continue\n",
    "        path = nx.shortest_path(graph,source=pickup_node,target=dropoff_node, weight='travel_time', method='dijkstra')\n",
    "        route_nodes_request = nodes.loc[path]\n",
    "        route_nodes_request_list = list(route_nodes_request.geometry.values)\n",
    "        line = LineString(route_nodes_request_list)\n",
    "        \n",
    "        route_line_request.append(line)\n",
    "        nodes_pair.append([pickup_node,dropoff_node])\n",
    "        time_r = ox.utils_graph.get_route_edge_attributes(graph,path,attribute='travel_time')\n",
    "        nodes_time.append(sum(time_r))\n",
    "    req_gdf = req_gdf[req_gdf.dropp != 1]\n",
    "    route_line_geom_request = gpd.GeoDataFrame(nodes_pair, geometry= route_line_request,columns=['pickup_node','dropoff_node'],index=req_gdf.index)\n",
    "    route_line_geom_request['pickup_datetime'] = req_gdf['pickup_datetime']\n",
    "    route_line_geom_request['trip_time']=nodes_time\n",
    "    route_line_geom_request['trip_length_ft'] = route_line_geom_request.geometry.length\n",
    "    return(route_line_geom_request,req_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vehicle position and time into a dataframe\n",
    "def convert_veh_coord(veh_data,graph):\n",
    "    # specify target CRS (from WGS84 to local projected crs(feets))\n",
    "    transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:2263\")\n",
    "    list_node=[]\n",
    "    veh_x = []\n",
    "    veh_y = []\n",
    "    for index,row in veh_data.iterrows():\n",
    "        v_x,v_y=transformer.transform(row['dropoff_latitude'],row['dropoff_longitude'])\n",
    "        v_node = ox.get_nearest_node(graph,(v_y,v_x),method='euclidean')\n",
    "        list_node.append(v_node)\n",
    "        veh_x.append(v_x)\n",
    "        veh_y.append(v_y)\n",
    "    df=veh_data.copy(deep=True)\n",
    "    df['dropoff_datetime'] = pd.to_datetime(veh_data['dropoff_datetime'])\n",
    "    df['veh_node'] = list_node\n",
    "    df['veh_x'] = veh_x\n",
    "    df['veh_y'] = veh_y\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time windows of a vehicle and requests based on waiting time and traveltime delay\n",
    "def create_time_windows(request_data,veh_data,waiting_time,delay_time):\n",
    "    time_win = []\n",
    "    time_req = ((pd.to_datetime(request_data.pickup_datetime, utc=True)- pd.Timestamp(\"1970-01-01\",tz='UTC'))// pd.Timedelta('1s'))\n",
    "    time_veh = (pd.to_datetime(veh_data.dropoff_datetime, utc=True)- pd.Timestamp(\"1970-01-01\",tz='UTC'))// pd.Timedelta('1s')\n",
    "    time_all = []\n",
    "    time_all.append(time_veh)\n",
    "    check_bool = isinstance(request_data, pd.DataFrame)\n",
    "    if check_bool==True:\n",
    "        time_req = time_req.to_list()\n",
    "        time_all.extend(time_req)\n",
    "    else:\n",
    "        time_all.append(time_req)\n",
    "        \n",
    "    min_t =  min(time_all)\n",
    "    df=request_data.copy(deep=True)\n",
    "    \n",
    "    if check_bool==True:  \n",
    "        df['pickup_datetime'] = [x - min_t for x in time_req]\n",
    "    else:\n",
    "        df['pickup_datetime'] = time_req - min_t\n",
    "    #add time window of the vehicle\n",
    "    time_win.append((time_veh - min_t,time_veh - min_t+90))\n",
    "    #add time window of requests\n",
    "    if check_bool==True: \n",
    "        for index,row in df.iterrows():\n",
    "            pickup_earliest = int(row['pickup_datetime'])\n",
    "            pickup_latest = pickup_earliest + waiting_time\n",
    "\n",
    "            dropoff_earliest = pickup_earliest + int(row['trip_time'])\n",
    "            dropoff_latest = dropoff_earliest + delay_time\n",
    "\n",
    "            time_win.append((pickup_earliest,pickup_latest))\n",
    "            time_win.append((dropoff_earliest,dropoff_latest))\n",
    "    else:\n",
    "        pickup_earliest = int(df['pickup_datetime'])\n",
    "        pickup_latest = pickup_earliest + waiting_time\n",
    "\n",
    "        dropoff_earliest = pickup_earliest + int(df['trip_time'])\n",
    "        dropoff_latest = dropoff_earliest + delay_time\n",
    "\n",
    "        time_win.append((pickup_earliest,pickup_latest))\n",
    "        time_win.append((dropoff_earliest,dropoff_latest))\n",
    "    \n",
    "    return (time_win,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of nodes, start with vehicle location as first row\n",
    "def combine_veh_req_nodes(request_data,veh_data):\n",
    "    #nodes_proj,edges_proj = ox.graph_to_gdfs(graph_proj)\n",
    "    nodes_all=[]\n",
    "    #add vehicle node\n",
    "    nodes_all.append(veh_data.veh_node)\n",
    "    #add requests' pickup and dropoff nodes\n",
    "    if isinstance(request_data, pd.DataFrame):\n",
    "        for index,row in request_data.iterrows():\n",
    "            nodes_all.append(row['pickup_node'])\n",
    "            nodes_all.append(row['dropoff_node'])\n",
    "    else:\n",
    "        nodes_all.append(request_data['pickup_node'])\n",
    "        nodes_all.append(request_data['dropoff_node'])\n",
    "    #create data for time matrix & distance matrix\n",
    "    data_dist=[]\n",
    "    data_time = []\n",
    "    for node1 in nodes_all:\n",
    "        df_node1 = df_all_nodes.loc[df_all_nodes['u']==node1]\n",
    "        row_dist=[]\n",
    "        row_time = []\n",
    "        for node2 in nodes_all:\n",
    "            if node1==node2:\n",
    "                row_dist.append(0)\n",
    "                row_time.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                df_node2 = df_node1.loc[df_node1['v']==node2]\n",
    "                row_dist.append(df_node2.length.item())\n",
    "                row_time.append(df_node2.travel_time.item())\n",
    "        data_dist.append(row_dist)\n",
    "        data_time.append(row_time)\n",
    "    data_time_noreturn = pd.DataFrame(data_time)\n",
    "    data_time_noreturn.loc[:,0] = 0\n",
    "    data_time_v2 = data_time_noreturn.values.tolist()\n",
    "    \n",
    "    data_dist_noreturn = pd.DataFrame(data_dist)\n",
    "    data_dist_noreturn.loc[:,0] = 0\n",
    "    data_dist_v2 = data_dist_noreturn.values.tolist()\n",
    "    \n",
    "    return(data_dist_v2,data_time_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of nodes, start with vehicle location as first row\n",
    "#now using sqlite database to store data\n",
    "def create_matrix_all_nodes(request_data,veh_data,graph_proj):\n",
    "    nodes_proj,edges_proj = ox.graph_to_gdfs(graph_proj)\n",
    "    nodes_all=[]\n",
    "    #add requests' pickup and dropoff nodes\n",
    "    if isinstance(request_data, pd.DataFrame):\n",
    "        for index,row in request_data.iterrows():\n",
    "            if row['pickup_node'] not in nodes_all:\n",
    "                nodes_all.append(row['pickup_node'])\n",
    "            if row['dropoff_node'] not in nodes_all:\n",
    "                nodes_all.append(row['dropoff_node']) \n",
    "    for index,row in veh_data.iterrows():\n",
    "        if row.veh_node not in nodes_all:\n",
    "            nodes_all.append(row.veh_node) \n",
    "    data_all_nodes=gpd.GeoDataFrame(columns=['u','v','geometry','length','travel_time'])\n",
    "    i=0\n",
    "    pbar = tqdm(total=len(nodes_all))\n",
    "    for node1 in nodes_all:\n",
    "        for node2 in nodes_all:\n",
    "            \n",
    "            if node1 == node2:\n",
    "                continue\n",
    "            else:\n",
    "                data_all_nodes_v2=pd.DataFrame(columns=['u','v','length','travel_time'])\n",
    "                path = nx.shortest_path(graph_proj,source=node1,target=node2, weight='travel_time')\n",
    "                #convert list of nodes from shortest path into a list\n",
    "                path_nodes = nodes_proj.loc[path]\n",
    "                route_list = list(path_nodes.geometry.values)\n",
    "                route_geom = LineString(route_list)\n",
    "                route_length = int(route_geom.length)\n",
    "                #get time\n",
    "                time_list = ox.utils_graph.get_route_edge_attributes(graph_proj,path,attribute='travel_time')\n",
    "                route_time = sum(time_list)\n",
    "                data_all_nodes_v2 = data_all_nodes_v2.append({'u':node1,'v':node2,'length':route_length,'travel_time':route_time},ignore_index=True)  \n",
    "                data_all_nodes_v2.to_sql('data', disk_engine, if_exists='append')\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    #return(data_all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demand for each request based on origin and destination its node\n",
    "def create_demand(request_data):\n",
    "    demand = [0]\n",
    "    a = 0\n",
    "    if isinstance(request_data, pd.DataFrame):\n",
    "        for index,row in request_data.iterrows():\n",
    "            a=index\n",
    "            demand.append(1)\n",
    "            demand.append(-1)\n",
    "    else:\n",
    "        demand.append(1)\n",
    "        demand.append(-1)\n",
    "    return(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create request pairs with nex index\n",
    "def create_pickup_delivery(request_data):\n",
    "    #request start from node 1 // depot=0\n",
    "    new_index_pair = []\n",
    "    b = 0\n",
    "    if isinstance(request_data, pd.DataFrame):\n",
    "        for n in range(len(request_data.index)):\n",
    "            new_index_pair.append([b+n+1,b+n+2])\n",
    "            b += 1\n",
    "    else:\n",
    "        new_index_pair.append([1,2])\n",
    "    return(new_index_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google OR-TOOLS function\n",
    "from __future__ import print_function\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "\n",
    "def create_data_model(distance_matrix,time_matrix,time_windows,requests,veh,req_demand,veh_capacity):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    data = {}\n",
    "    data['distance_matrix'] = distance_matrix\n",
    "    data['time_matrix'] = time_matrix\n",
    "    data['time_windows'] = time_windows\n",
    "    data['pickups_deliveries'] = requests\n",
    "    data['num_vehicles'] = veh\n",
    "    data['depot'] = 0\n",
    "    data['demands'] = req_demand\n",
    "    data['vehicle_capacities'] = [veh_capacity]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solution(data, manager, routing, solution):\n",
    "    \"\"\"Prints solution on console.\"\"\"\n",
    "    time_dimension = routing.GetDimensionOrDie('Time')\n",
    "    total_distance = 0\n",
    "    total_time = 0\n",
    "    node_all = []\n",
    "    total_load = 0\n",
    "    check_share = 0\n",
    "    passenger_delay = 0\n",
    "    pickup_d = 0\n",
    "    dropoff_d = 0\n",
    "    dropoff_t = 0\n",
    "    total_waiting_t = 0\n",
    "    total_trip_dist = 0\n",
    "    total_trip_time = 0\n",
    "    pickup_t = 0\n",
    "    for vehicle_id in range(data['num_vehicles']):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        plan_output = 'Route for vehicle {}:\\n'.format(vehicle_id)\n",
    "        route_load = 0\n",
    "        route_distance = 0\n",
    "        \n",
    "        while not routing.IsEnd(index):\n",
    "            time_var = time_dimension.CumulVar(index)\n",
    "#             plan_output += '{0} Time({1},{2}) -> '.format(\n",
    "\n",
    "            \n",
    "            node_index = manager.IndexToNode(index)\n",
    "            plan_output += '{0} Time({1},{2},{3})'.format(\n",
    "                manager.IndexToNode(index), solution.Min(time_var),\n",
    "                solution.Max(time_var),data['time_windows'][node_index][0])\n",
    "            route_load += data['demands'][node_index]\n",
    "            if data['demands'][node_index]==-1:\n",
    "                passenger_delay += solution.Min(time_var) - data['time_windows'][node_index][0]\n",
    "                \n",
    "                dropoff_t = solution.Min(time_var)\n",
    "                total_trip_time += dropoff_t - pickup_t\n",
    "                \n",
    "                dropoff_d =  route_distance\n",
    "                total_trip_dist += dropoff_d - pickup_d\n",
    "                \n",
    "            if data['demands'][node_index]==1:\n",
    "                total_waiting_t += (solution.Min(time_var) - data['time_windows'][node_index][0])\n",
    "                \n",
    "                pickup_t = solution.Min(time_var)\n",
    "                pickup_d = route_distance\n",
    "                \n",
    "            plan_output += ' {0} Load({1}) -> '.format(node_index, route_load)\n",
    "            \n",
    "            if route_load > check_share:\n",
    "                check_share = route_load\n",
    "            node_all.append(manager.IndexToNode(index))\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(\n",
    "                node_index, index, vehicle_id)\n",
    "        time_var = time_dimension.CumulVar(index)\n",
    "        plan_output += '{0} Time({1},{2})\\n'.format(manager.IndexToNode(index),\n",
    "                                                    solution.Min(time_var),\n",
    "                                                    solution.Max(time_var))\n",
    "        plan_output += ' {0} Load({1})\\n'.format(manager.IndexToNode(index),\n",
    "                                                 route_load)\n",
    "        plan_output += 'Time of the route: {}sec\\n'.format(\n",
    "            solution.Min(time_var))\n",
    "        node_all.append(manager.IndexToNode(index))\n",
    "        plan_output += 'Load of the route: {}\\n'.format(route_load)\n",
    "        total_time += solution.Min(time_var)\n",
    "        total_load += route_load\n",
    "        total_distance += route_distance\n",
    "    return(node_all,total_time,total_distance,check_share,passenger_delay,[total_waiting_t,total_trip_dist,total_trip_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_routing(data_dist,data_time,time_win,req_pair,veh_no,req_demand,veh_capacity):\n",
    "    # Instantiate the data problem.\n",
    "    data = create_data_model(data_dist,data_time,time_win,req_pair,veh_no,req_demand,veh_capacity)\n",
    "    # Create the routing index manager.\n",
    "    manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),data['num_vehicles'], data['depot'])\n",
    "\n",
    "    # Create Routing Model.\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "    # Create and register a transit callback.\n",
    "    def time_callback(from_index, to_index):\n",
    "        \"\"\"Returns the travel time between the two nodes.\"\"\"\n",
    "        \n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return data['time_matrix'][from_node][to_node]\n",
    "\n",
    "    transit_callback_index = routing.RegisterTransitCallback(time_callback)\n",
    "    # Define cost of each arc.\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "    # Convert from routing variable Index to time matrix NodeIndex.\n",
    "    # Add Time Windows constraint.\n",
    "    time = 'Time'\n",
    "    routing.AddDimension(\n",
    "        transit_callback_index,\n",
    "        60,  # allow waiting time\n",
    "        3600,  # maximum time per vehicle\n",
    "        False,  # Don't force start cumul to zero.\n",
    "        time)\n",
    "    time_dimension = routing.GetDimensionOrDie(time)\n",
    "    \n",
    "    # Add time window constraints for each location except depot.\n",
    "    for location_idx, time_window in enumerate(data['time_windows']):    \n",
    "        if location_idx == 0:\n",
    "            continue\n",
    "        index = manager.NodeToIndex(location_idx)\n",
    "        time_dimension.CumulVar(index).SetRange(time_window[0], time_window[1])\n",
    "    # Add time window constraints for each vehicle start node.\n",
    "    for vehicle_id in range(data['num_vehicles']):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        time_dimension.CumulVar(index).SetRange(data['time_windows'][0][0],\n",
    "                                                data['time_windows'][0][1])\n",
    "    #set time value\n",
    "    time_dimension.SetSpanCostCoefficientForAllVehicles(99)\n",
    "    \n",
    "    # Define distance of each arc (added).\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the manhattan distance between the two nodes.\"\"\"\n",
    "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "    transit_callback_index_distance = routing.RegisterTransitCallback(distance_callback)\n",
    "    \n",
    "    # Add Distance dimension (added).\n",
    "    dimension_name = 'Distance'\n",
    "    routing.AddDimension(\n",
    "        transit_callback_index_distance,\n",
    "        0,  # no slack\n",
    "        300000000,  # vehicle maximum travel distance\n",
    "        True,  # start cumul to zero\n",
    "        dimension_name)\n",
    "    distance_dimension = routing.GetDimensionOrDie(dimension_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define Transportation Requests.\n",
    "    for request in data['pickups_deliveries']:\n",
    "        pickup_index = manager.NodeToIndex(request[0])\n",
    "        delivery_index = manager.NodeToIndex(request[1])\n",
    "        routing.AddPickupAndDelivery(pickup_index, delivery_index)\n",
    "        routing.solver().Add(\n",
    "            routing.VehicleVar(pickup_index) == routing.VehicleVar(\n",
    "                delivery_index))\n",
    "#change distance_dimension to time_dimension       \n",
    "        routing.solver().Add(\n",
    "            time_dimension.CumulVar(pickup_index) <=\n",
    "            time_dimension.CumulVar(delivery_index))\n",
    " \n",
    "    # Add Capacity constraint.\n",
    "    def demand_callback(from_index):\n",
    "        \"\"\"Returns the demand of the node.\"\"\"\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        return data['demands'][from_node]\n",
    "    demand_callback_index = routing.RegisterUnaryTransitCallback(\n",
    "        demand_callback)\n",
    "    routing.AddDimensionWithVehicleCapacity(\n",
    "        demand_callback_index,\n",
    "        0,  # null capacity slack\n",
    "        data['vehicle_capacities'],  # vehicle maximum capacities\n",
    "        True,  # start cumul to zero\n",
    "        'Capacity')\n",
    " \n",
    "    # Instantiate route start and end times to produce feasible times.\n",
    "    for i in range(data['num_vehicles']):\n",
    "        routing.AddVariableMinimizedByFinalizer(\n",
    "            time_dimension.CumulVar(routing.Start(i)))\n",
    "        routing.AddVariableMinimizedByFinalizer(\n",
    "            time_dimension.CumulVar(routing.End(i)))\n",
    "\n",
    "\n",
    "\n",
    "    # Setting first solution heuristic.\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "    # Solve the problem.\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "    if solution:\n",
    "        result_nodes,result_time,result_dist,check_share,passenger_delay,total_waiting_t = print_solution(data, manager, routing, solution)\n",
    "        return(solution,result_nodes,result_time,result_dist,check_share,passenger_delay,total_waiting_t)\n",
    "    else:\n",
    "        return(solution,[0],[0],[0],[0],[0],[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(request_raw,veh_raw,graph):\n",
    "    #convert request coord\n",
    "    request_proj = convert_req_coord(request_raw)\n",
    "    #get path of each request and clean request\n",
    "    req_line_geom, clean_request_proj = map_matching_paths(graph,request_proj)\n",
    "    #convert vehicle coord\n",
    "    man_veh_new = convert_veh_coord(veh_raw,graph)\n",
    "    return(req_line_geom,man_veh_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrp_input_preparation(req_data,veh_data,waiting_t,delay_t,graph):\n",
    "    #get time window for the specified requests\n",
    "    time_win,time_df = create_time_windows(req_data,veh_data,waiting_t,delay_t)\n",
    "    #get dist&time matrix for the specified requests and a specfied vehicle\n",
    "    data_dist,data_time = combine_veh_req_nodes(req_data,veh_data)\n",
    "    #get request pair with new index\n",
    "    req_pair = create_pickup_delivery(req_data)\n",
    "    #get demand of a specified requests\n",
    "    req_demand = create_demand(req_data)\n",
    "    return(data_dist,data_time,time_win,req_pair,req_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of the process: calling data preparation function and save all data to a database\n",
    "request_data, vehicle_data = data_preparation(man_req,man_veh,graph_proj)\n",
    "disk_engine = create_engine('sqlite:///nyc_all_nodes.db')\n",
    "\n",
    "# create_matrix_all_nodes(request_data,vehicle_data,graph_proj)\n",
    "df_all_nodes = pd.read_sql_query('SELECT *' 'FROM data' , disk_engine)\n",
    "df_all_nodes = df_all_nodes.astype('int64')\n",
    "df_all_nodes = df_all_nodes.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constraints\n",
    "vehicle_no = 1\n",
    "capacity = 4\n",
    "waiting_t = 300\n",
    "delay_t = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RV-graph\n",
    "\n",
    "# create RV-graph for a vehicle and a reqeust\n",
    "now1 = datetime.now()\n",
    "request_copy =request_data.copy(deep=True)\n",
    "edges_rv = pd.DataFrame()\n",
    "count_i = 0\n",
    "\n",
    "with tqdm(total=vehicle_data.shape[0]) as pbar:\n",
    "    for index_veh,row_veh in vehicle_data.iterrows():\n",
    "        \n",
    "        for index, row in request_data.iterrows():\n",
    "            data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data.loc[index],row_veh,waiting_t,delay_t,graph_proj)\n",
    "            #print(1)\n",
    "            solution,result_nodes,result_time,result_dist,check_share,passenger_delay,total_waiting_t = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "            #print(2)\n",
    "            if solution:\n",
    "                request_copy.loc[index,'vrp']=1\n",
    "                #print(9999)\n",
    "                #rv_graph.add_edge(row.pickup_node,row_veh.veh_node)\n",
    "                edges_rv.loc[count_i,'pickup_node'] = int(row.pickup_node)\n",
    "                edges_rv.loc[count_i,'veh_node'] = int(row_veh.veh_node)\n",
    "                #edges_rv.loc[count_i,'nodes_list'] = result_nodes\n",
    "                edges_rv.loc[count_i,'result_time'] = int(result_time)\n",
    "                edges_rv.loc[count_i,'result_dist'] = int(result_dist)\n",
    "                edges_rv.loc[count_i,'req_index'] = int(index)\n",
    "                edges_rv.loc[count_i,'veh_index'] = int(index_veh)\n",
    "                edges_rv.loc[count_i,'passengers_delay'] = int(passenger_delay)\n",
    "                count_i += 1\n",
    "            else:\n",
    "                request_copy.loc[index,'vrp']=0\n",
    "                #print('----')\n",
    "        pbar.update(1)\n",
    "now2 = datetime.now()\n",
    "print(now2-now1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rv graph for request1-request2\n",
    "now1 = datetime.now()\n",
    "request_copy_v2 =request_data.copy(deep=True)\n",
    "edges_rr = pd.DataFrame()\n",
    "count_i = 0\n",
    "\n",
    "with tqdm(total=request_data.shape[0]) as pbar:\n",
    "    for index_veh,row_veh in request_data.iterrows():\n",
    "        row_veh_convert=pd.DataFrame(columns=['dropoff_datetime','veh_node'])\n",
    "        row_veh_convert.loc[0,'dropoff_datetime'] = row_veh.pickup_datetime\n",
    "        row_veh_convert.loc[0,'veh_node'] = row_veh['pickup_node']\n",
    "        for index, row in request_data.iterrows():\n",
    "            if (index==index_veh):\n",
    "                continue\n",
    "            request_data_2 = pd.DataFrame(columns=['pickup_node', 'dropoff_node', 'geometry', 'pickup_datetime',\n",
    "       'trip_time', 'trip_length_ft'])\n",
    "            request_data_2.loc[0]=row_veh\n",
    "            request_data_2.loc[1]=row\n",
    "            \n",
    "            data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data_2,row_veh_convert.iloc[0],waiting_t,delay_t,graph_proj)\n",
    "            #print(1)\n",
    "            solution,result_nodes,result_time,result_dist,check_share,passenger_delay,total_waiting_t = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "            #print(2)\n",
    "            if solution:\n",
    "                request_copy_v2.loc[index,'vrp']=1\n",
    "                #rv_graph.add_edge(row.pickup_node,row_veh.veh_node)\n",
    "                edges_rr.loc[count_i,'pickup2_node'] = int(row.pickup_node)\n",
    "                edges_rr.loc[count_i,'pickup1_node'] = int(row_veh_convert.veh_node)\n",
    "                #edges_rv.loc[count_i,'nodes_list'] = (result_nodes)\n",
    "                edges_rr.loc[count_i,'result_time'] = int(result_time)\n",
    "                edges_rr.loc[count_i,'result_dist'] = int(result_dist)\n",
    "                edges_rr.loc[count_i,'req2_index'] = int(index)\n",
    "                edges_rr.loc[count_i,'req1_index'] = int(index_veh)\n",
    "                edges_rr.loc[count_i,'share'] = check_share\n",
    "                edges_rr.loc[count_i,'passengers_delay'] = int(passenger_delay)\n",
    "                data_time[1][2]\n",
    "                for node_new in result_nodes:\n",
    "                    data_time\n",
    "                    \n",
    "                count_i += 1\n",
    "            else:\n",
    "                request_copy_v2.loc[index,'vrp']=0\n",
    "                #print('----')\n",
    "        pbar.update(1)\n",
    "now2 = datetime.now()\n",
    "print(now2-now1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output of rv-graph\n",
    "edges_rv = edges_rv.astype('int64')\n",
    "edges_rv.to_csv('edges_rv_wait-5_delay-7.csv',index=True)\n",
    "edges_rr = edges_rr.astype('int64')\n",
    "edges_rr = edges_rr.loc[edges_rr['share']==2]\n",
    "edges_rr.to_csv('edges_rr_wait-5_delay-7.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RTV-graph\n",
    "df_rv = pd.read_csv(\"edges_rv_wait-3_delay-5.csv\",index_col=0)\n",
    "df_rr = pd.read_csv(\"edges_rr_wait-3_delay-5.csv\",index_col=0)\n",
    "df_rr = df_rr.loc[df_rr['share']==2]\n",
    "rv_graph_50 = nx.Graph()\n",
    "rr_graph = nx.Graph()\n",
    "RTV_graph = nx.Graph()\n",
    "RTV_node=pd.DataFrame(columns=['node_index','x','y','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_no = 1\n",
    "capacity = 4\n",
    "waiting_t = 180\n",
    "delay_t = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 50% vehicle\n",
    "# df_rv_50 = df_rv.loc[df_rv['veh_index'].isin(man_veh_50.index)]\n",
    "df_rv_50 = df_rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "now1 = datetime.now()\n",
    "for index,row in df_rv_50.iterrows():\n",
    "    x_req = nodes_proj.loc[row.pickup_node].x\n",
    "    y_req = nodes_proj.loc[row.pickup_node].y\n",
    "    rv_graph_50.add_node(row['req_index'],pos=(x_req,y_req))\n",
    "    rr_graph.add_node(row['req_index'],pos=(x_req,y_req))\n",
    "    RTV_graph.add_node(row['req_index'],pos=(x_req,y_req),node_type='request')\n",
    "    RTV_node = RTV_node.append({'node_index':row['req_index'],'x':x_req,'y':y_req,'type':'request'},ignore_index=True)\n",
    "for index,row in df_rv_50.iterrows():\n",
    "    x_veh = nodes_proj.loc[row.veh_node].x\n",
    "    y_veh = nodes_proj.loc[row.veh_node].y\n",
    "    rv_graph_50.add_node(row['veh_index'],pos=(x_veh,y_veh))\n",
    "    RTV_graph.add_node(row['veh_index'],pos=(x_veh,y_veh),node_type='vehicle')\n",
    "    RTV_node = RTV_node.append({'node_index':row['veh_index'],'x':x_veh,'y':y_veh,'type':'vehicle'},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTV_node = RTV_node.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in df_rv_50.iterrows():\n",
    "    rv_graph_50.add_edge(row.req_index,row.veh_index,t_time=row.result_time,dist=row.result_dist,delay=row.passengers_delay)\n",
    "for index,row in df_rr.iterrows():\n",
    "    rr_graph.add_edge(row.req1_index,row.req2_index,t_time=row.result_time,dist=row.result_dist,delay=row.passengers_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_engine_T = create_engine('sqlite:///T_wait-3_delay-5_v2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=df_rv_50.veh_index.unique().size)\n",
    "T_1 = pd.DataFrame(columns=['request_index','request1'])\n",
    "T_2 = pd.DataFrame(columns=['request_index','request1','request2'])\n",
    "T_3 = pd.DataFrame(columns=['request_index','request1','request2','request3'])\n",
    "T_4 = pd.DataFrame(columns=['request_index','request1','request2','request3','request4'])\n",
    "for vehicle in df_rv_50.veh_index.unique():\n",
    "    T_sql = pd.DataFrame(columns=['veh_index','request_index','size','r1','r2','r3','r4','delay','total_time','dist','pas_wait_t','pas_wait_dist','pas_trip_t'])\n",
    "    T1_per_veh = []\n",
    "#     pbar2 = tqdm(total=4)\n",
    "    for edge in rv_graph_50.edges.data(nbunch=vehicle):\n",
    "        \n",
    "        if edge[1] not in T_1.request_index.values:\n",
    "            T_1 = T_1.append({'request_index':edge[1],'request1':edge[1]},ignore_index=True)\n",
    "\n",
    "        delay=edge[2]['delay']\n",
    "        trip_time=edge[2]['t_time']\n",
    "        trip_dist=edge[2]['dist']\n",
    "        T1_per_veh.append(edge[1])\n",
    "        T_sql = T_sql.append({'veh_index':vehicle,'request_index':str(edge[1]),'size':1,'r1':edge[1],'delay':delay,'total_time':trip_time,'dist':trip_dist},ignore_index=True)\n",
    "#     pbar2.update(1)\n",
    "    T2_per_veh=[]\n",
    "    for r1 in T1_per_veh:\n",
    "        for r2 in T1_per_veh:\n",
    "            if r1==r2:\n",
    "                continue\n",
    "            test_array_t1= [r1,r2]\n",
    "            test_array_t1.sort() \n",
    "            if rr_graph.has_edge(r1,r2) and test_array_t1 not in T2_per_veh:\n",
    "                check_req_index = str('{}_{}'.format(r1,r2))\n",
    "\n",
    "                data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data.loc[[r1,r2]],vehicle_data.loc[vehicle],waiting_t,delay_t,graph_proj)\n",
    "                solution,result_nodes,result_time,result_dist,check_share,passenger_delay,performance_data = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "                if solution and check_share==2:\n",
    "                    total_waiting_t = performance_data[0]\n",
    "                    total_trip_dist = performance_data[1]\n",
    "                    total_trip_time = performance_data[2]\n",
    "                    if check_req_index not in T_2.request_index:\n",
    "                        T_2 = T_2.append({'request_index':check_req_index ,'request1':r1,'request2':r2},ignore_index=True)\n",
    "                    T_sql = T_sql.append({'veh_index':vehicle,'request_index':check_req_index,'size':2,'r1':r1,'r2':r2,'delay':passenger_delay,'total_time':result_time,'dist':result_dist,'pas_wait_t':total_waiting_t,'pas_wait_dist':total_trip_dist,'pas_trip_t':total_trip_time},ignore_index=True)\n",
    "                    T2_per_veh.append(test_array_t1)\n",
    "#     pbar2.update(1)\n",
    "    T3_per_veh=[]\n",
    "    for sub_T2 in T2_per_veh:\n",
    "        for sub_T1 in T1_per_veh:\n",
    "            test_array=[]\n",
    "            if sub_T1 not in sub_T2:\n",
    "                test_array.append(sub_T1)\n",
    "                test_array.extend(sub_T2)\n",
    "                test_array.sort()\n",
    "                for sub_com_T3 in combinations(test_array,2):\n",
    "                    if sub_com_T3 not in T2_per_veh:\n",
    "                        continue\n",
    "                if test_array not in T3_per_veh:\n",
    "                    data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data.loc[test_array],vehicle_data.loc[vehicle],waiting_t,delay_t,graph_proj)\n",
    "                    solution,result_nodes,result_time,result_dist,check_share,passenger_delay,performance_data = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "                    if solution and check_share==3:\n",
    "                        total_waiting_t = performance_data[0]\n",
    "                        total_trip_dist = performance_data[1]\n",
    "                        total_trip_time = performance_data[2]\n",
    "                        check_req_index = str('{}_{}_{}'.format(test_array[0],test_array[1],test_array[2]))\n",
    "                        if check_req_index not in T_3.request_index:\n",
    "                            T_3 = T_3.append({'request_index':check_req_index ,'request1':test_array[0],'request2':test_array[1],'request3':test_array[2]},ignore_index=True)\n",
    "                        T3_per_veh.append(test_array)\n",
    "                        T_sql = T_sql.append({'veh_index':vehicle,'request_index':check_req_index,'size':3,'r1':test_array[0],'r2':test_array[1],'r3':test_array[2],'delay':passenger_delay,'total_time':result_time,'dist':result_dist,'pas_wait_t':total_waiting_t,'pas_wait_dist':total_trip_dist,'pas_trip_t':total_trip_time},ignore_index=True)\n",
    "#                         T_sql.to_sql('data', disk_engine_T, if_exists='append')\n",
    "#     pbar2.update(1)\n",
    "    flat_list_T3 = [item for sublist in T3_per_veh for item in sublist]\n",
    "    flat_list_T3 = list(set(flat_list_T3))\n",
    "    T4_per_veh = []\n",
    "    for sub_T3 in T3_per_veh:\n",
    "        for com_T1 in flat_list_T3:\n",
    "            if com_T1 in sub_T3:\n",
    "                continue\n",
    "            test_array=[]\n",
    "            test_array.append(com_T1)\n",
    "            test_array.extend(sub_T3)\n",
    "            test_array.sort()\n",
    "            if test_array in T4_per_veh:\n",
    "                continue\n",
    "            \n",
    "            for sub_com_T4 in combinations(test_array,3):\n",
    "                if sub_com_T4 not in T3_per_veh:\n",
    "                    continue    \n",
    "            data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data.loc[test_array],vehicle_data.loc[vehicle],waiting_t,delay_t,graph_proj)\n",
    "            solution,result_nodes,result_time,result_dist,check_share,passenger_delay,performance_data = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "            if solution and check_share==4:\n",
    "                total_waiting_t = performance_data[0]\n",
    "                total_trip_dist = performance_data[1]\n",
    "                total_trip_time = performance_data[2]\n",
    "                check_req_index = str('{}_{}_{}_{}'.format(test_array[0],test_array[1],test_array[2],test_array[3]))\n",
    "                if check_req_index not in T_4.request_index:\n",
    "                    T_4 = T_4.append({'request_index':check_req_index ,'request1':test_array[0],'request2':test_array[1],'request3':test_array[2],'request4':test_array[3]},ignore_index=True)\n",
    "                T4_per_veh.append(test_array)\n",
    "                T_sql = T_sql.append({'veh_index':vehicle,'request_index':check_req_index,'size':4,'r1':test_array[0],'r2':test_array[1],'r3':test_array[2],'r4':test_array[3],'delay':passenger_delay,'total_time':result_time,'dist':result_dist,'pas_wait_t':total_waiting_t,'pas_wait_dist':total_trip_dist,'pas_trip_t':total_trip_time},ignore_index=True)\n",
    "                \n",
    "                \n",
    "#     pbar2.update(1)\n",
    "#     pbar2.close()\n",
    "    T_sql.to_sql('data', disk_engine_T, if_exists='append')\n",
    "    pbar.update(1)\n",
    "pbar.close()                \n",
    "now2 = datetime.now()\n",
    "print(now2-now1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RTV graph for future optimization\n",
    "T.to_csv('rtv_allveh_wait-5_delay-10_first-run.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in rv_graph_50.edges.data(nbunch=6087):\n",
    "    print(a[2]['dist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative optimization method: Greedy\n",
    "\n",
    "T=pd.read_csv('rtv_50veh_first-run.csv')\n",
    "T_sorted = T.sort_values(by=['delay'])\n",
    "T_greedy=pd.DataFrame()\n",
    "req_greedy = request_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_greedy['assigned_veh']=0\n",
    "req_greedy['assigned_trip']=0\n",
    "for index,row in T_sorted.loc[T_sorted['size']==4].iterrows():\n",
    "    if all(i ==0 for i in req_greedy.loc[[row.r1,row.r2,row.r3,row.r4],'assigned_veh'].tolist()) and row.veh_index not in req_greedy['assigned_veh'].tolist():\n",
    "        req_greedy.loc[[row.r1,row.r2,row.r3,row.r4],'assigned_veh']=row.veh_index\n",
    "        req_greedy.loc[[row.r1,row.r2,row.r3,row.r4],'assigned_trip']=row.request_index\n",
    "        T_greedy = T_greedy.append(row)\n",
    "\n",
    "for index,row in T_sorted.loc[T_sorted['size']==3].iterrows():\n",
    "    if all(i ==0 for i in req_greedy.loc[[row.r1,row.r2,row.r3],'assigned_veh'].tolist()) and row.veh_index not in req_greedy['assigned_veh'].tolist():\n",
    "        req_greedy.loc[[row.r1,row.r2,row.r3],'assigned_veh']=row.veh_index\n",
    "        req_greedy.loc[[row.r1,row.r2,row.r3],'assigned_trip']=row.request_index\n",
    "        T_greedy = T_greedy.append(row)\n",
    "        \n",
    "for index,row in T_sorted.loc[T_sorted['size']==2].iterrows():\n",
    "    if all(i ==0 for i in req_greedy.loc[[row.r1,row.r2],'assigned_veh'].tolist()) and row.veh_index not in req_greedy['assigned_veh'].tolist():\n",
    "        req_greedy.loc[[row.r1,row.r2],'assigned_veh']=row.veh_index\n",
    "        req_greedy.loc[[row.r1,row.r2],'assigned_trip']=row.request_index\n",
    "        T_greedy = T_greedy.append(row)\n",
    "for index,row in T_sorted.loc[T_sorted['size']==1].iterrows():\n",
    "    if req_greedy.loc[row.r1,'assigned_veh'] == 0 and row.veh_index not in req_greedy['assigned_veh'].tolist():\n",
    "#         print(row.veh_index)\n",
    "        req_greedy.loc[row.r1,'assigned_veh']=row.veh_index\n",
    "        req_greedy.loc[row.r1,'assigned_trip']=row.request_index\n",
    "        T_greedy = T_greedy.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_greedy['assigned_veh'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_rv_filtered = df_rv['req_index'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process Optimization result from an imported csv \n",
    "df = pd.read_csv('all_ilp_200914.csv')\n",
    "capacity = 4\n",
    "vehicle_no = 1\n",
    "count_none = 0\n",
    "not_feasible = []\n",
    "for index,row in df.iterrows():\n",
    "    if row.vehicle == \"rejected\":\n",
    "        continue\n",
    "    trip_list = [int(x) for x in str(row.trip).split(\"_\")]\n",
    "    if len(trip_list)==1:\n",
    "        trip_each = trip_list[0]\n",
    "    else:\n",
    "        trip_each = trip_list\n",
    "    vehicle = float(row.vehicle)\n",
    "    waiting_t = row.waiting_time*60\n",
    "    delay_t = row.ride_time*60\n",
    "    \n",
    "    data_dist,data_time,time_win,req_pair,req_demand = vrp_input_preparation(request_data.loc[trip_each],vehicle_data.loc[vehicle],waiting_t,delay_t,graph_proj)\n",
    "    solution,result_nodes,result_time,result_dist,check_share,passenger_delay,performance_data = vehicle_routing(data_dist,data_time,time_win,req_pair,vehicle_no,req_demand,capacity)\n",
    "    if solution:\n",
    "        total_waiting_t = performance_data[0]\n",
    "        total_trip_dist = performance_data[1]\n",
    "        total_trip_time = performance_data[2]\n",
    "        df.loc[index,'veh_dist'] = result_dist\n",
    "        df.loc[index,'pas_wait_time'] = total_waiting_t\n",
    "        df.loc[index,'pas_wait_dist'] = total_trip_dist\n",
    "        df.loc[index,'pas_trip_time'] = total_trip_time\n",
    "    else:\n",
    "        count_none += 1\n",
    "        not_feasible.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ride_time_delay'] = df['delay']-df['pas_wait_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['fleet_size','waiting_time','ride_time','capacity'],as_index=False).sum('trip_size_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
